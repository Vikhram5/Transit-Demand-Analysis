{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4d160d3",
   "metadata": {},
   "source": [
    "## Generating all final ETM_files with mapping from external files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73ce0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for all the dates from 01 to 31 - latest etm files \n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Directories / folder\n",
    "ETM_folder = \"Latest_ETM_Data\"\n",
    "unmatched_stops = \"Match\"\n",
    "\n",
    "os.makedirs(ETM_folder, exist_ok=True)\n",
    "os.makedirs(unmatched_stops, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6bd03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loop for all dates \n",
    "\n",
    "for date in range(1, 32):\n",
    "    date_str = f\"{date:02}\"\n",
    "    \n",
    "    try:\n",
    "        print(f\"Processing for 2024-07-{date_str}...\")\n",
    "        \n",
    "        ticket_df = pd.read_csv(f'ETM_Data/Ticket-Data-2024-07-{date_str}.csv')\n",
    "        route_df = pd.read_csv('final_routes_directions.csv')\n",
    "        \n",
    "        ticket_df = ticket_df.merge(route_df[['Trip_Origin', 'Trip_Destination', 'Direction_Route']], \n",
    "                                    on=['Trip_Origin', 'Trip_Destination'], \n",
    "                                    how='left')\n",
    "        ticket_df.rename(columns={'Direction_Route': 'Direction_route'}, inplace=True)\n",
    "\n",
    "        # Process stop names and directions\n",
    "        ticket_df['source'] = ticket_df['source'].str.upper().str.split().str.join(' ')\n",
    "        ticket_df['destination'] = ticket_df['destination'].str.upper().str.split().str.join(' ')\n",
    "\n",
    "        stops_df = pd.read_csv('latest_stops_centroid_numbering.csv')\n",
    "        stops_df['DIRECTION'] = stops_df['DIRECTION'].str.upper().str.split().str.join(' ')\n",
    "        stops_df['STOP NAME'] = stops_df['Stop Name'].str.upper().str.split().str.join(' ')\n",
    "\n",
    "        # Map original and renamed stops\n",
    "        final_stops_df = pd.read_csv('stops_mapping.csv')\n",
    "        mapping_stops = final_stops_df.set_index('Stops')['Renamed Stops'].to_dict()\n",
    "\n",
    "        ticket_df['source'] = ticket_df['source'].map(mapping_stops).fillna(ticket_df['source'])\n",
    "        ticket_df['destination'] = ticket_df['destination'].map(mapping_stops).fillna(ticket_df['destination'])\n",
    "\n",
    "        stops_df_unique = stops_df.drop_duplicates(subset=['STOP NAME', 'DIRECTION'])\n",
    "\n",
    "        # Define merge_and_insert function\n",
    "        def merge_and_insert(ticket_df, stops_df, stop_column, direction_column):\n",
    "            ticket_df = ticket_df.merge(\n",
    "                stops_df[['STOP.NO', 'STOP NAME', 'DIRECTION']],\n",
    "                how='left',\n",
    "                left_on=[stop_column, direction_column],\n",
    "                right_on=['STOP NAME', 'DIRECTION']\n",
    "            )\n",
    "            stop_no_column = f\"{stop_column}_stop_no\"\n",
    "            ticket_df = ticket_df.rename(columns={'STOP.NO': stop_no_column}).drop(columns=['STOP NAME', 'DIRECTION'])\n",
    "            stop_no = ticket_df.pop(stop_no_column)\n",
    "            stop_index = ticket_df.columns.get_loc(stop_column) + 1  \n",
    "            ticket_df.insert(stop_index, stop_no_column, stop_no)\n",
    "            return ticket_df\n",
    "\n",
    "        # Insert stop numbers\n",
    "        ticket_df = merge_and_insert(ticket_df, stops_df_unique, 'source', 'Direction_route')\n",
    "        ticket_df = merge_and_insert(ticket_df, stops_df_unique, 'destination', 'Direction_route')\n",
    "\n",
    "        # Process unmatched stops\n",
    "        nodirection_stops_unique = stops_df[stops_df['DIRECTION'].isna()].drop_duplicates(subset=['STOP NAME'])\n",
    "\n",
    "        def update_stop_no(ticket_df, stops_df, stop_column, stop_no_column):\n",
    "            updated_df = ticket_df.merge(\n",
    "                stops_df[['STOP.NO', 'STOP NAME']],\n",
    "                how='left',\n",
    "                left_on=stop_column,\n",
    "                right_on='STOP NAME'\n",
    "            )\n",
    "            ticket_df.loc[ticket_df[stop_no_column].isna(), stop_no_column] = updated_df['STOP.NO']\n",
    "            return ticket_df\n",
    "\n",
    "        ticket_df = update_stop_no(ticket_df, nodirection_stops_unique, 'source', 'source_stop_no')\n",
    "        ticket_df = update_stop_no(ticket_df, nodirection_stops_unique, 'destination', 'destination_stop_no')\n",
    "\n",
    "        ticket_df = ticket_df.loc[:, ~ticket_df.columns.str.contains('^Unnamed')]\n",
    "        ticket_df.to_csv(f'Temporary_File_{date_str}.csv', index=False)\n",
    "\n",
    "        df = pd.read_csv(f'Temporary_File_{date_str}.csv', index_col=False)\n",
    "        df = df.loc[:, ~df.columns.str.contains('^Unnamed')]\n",
    "\n",
    "        stops_df_unique = stops_df[['STOP NAME', 'CENTROID NUMBERING']].drop_duplicates(subset='STOP NAME')\n",
    "\n",
    "        df = df.merge(stops_df_unique, left_on='source', right_on='STOP NAME', how='left')\n",
    "        df = df.rename(columns={'CENTROID NUMBERING': 'source_zonal_centroid_number'})\n",
    "        df = df.drop(columns=['STOP NAME'])\n",
    "        cols = df.columns.tolist()\n",
    "        source_idx = cols.index('source_stop_no')\n",
    "        cols.insert(source_idx + 1, cols.pop(cols.index('source_zonal_centroid_number')))\n",
    "        df = df[cols]\n",
    "\n",
    "        df = df.merge(stops_df_unique, left_on='destination', right_on='STOP NAME', how='left')\n",
    "        df = df.rename(columns={'CENTROID NUMBERING': 'destination_zonal_centroid_number'})\n",
    "        df = df.drop(columns=['STOP NAME'])\n",
    "        cols = df.columns.tolist()\n",
    "        destination_idx = cols.index('destination_stop_no')\n",
    "        cols.insert(destination_idx + 1, cols.pop(cols.index('destination_zonal_centroid_number')))\n",
    "        df = df[cols]\n",
    "\n",
    "        df.to_csv(f'{ETM_folder}/Final_Ticket_data_2024-07-{date_str}.csv', index=False)\n",
    "        print(f\"File saved to {ETM_folder}/Final_Ticket_data_2024-07-{date_str}.csv\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found for 2024-07-{date_str}, skipping.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred for 2024-07-{date_str}: {e}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e518c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
